{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54c04ed3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d7d6ef4b3917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m# Run for every frame in the videostream; img = each frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mgrabbed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# grab the frames and store them as img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mimgContour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# initialize the output imgContour as a copy of img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Apply Gaussian Blur Filter, (9,9) kernel to smooth the image and reduce noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Created by Vlad Marascu for GDP ADD02 Group 2020\n",
    "# 04/06/2020\n",
    "\n",
    "# Main entrance points detection script: uses the calibration.py script and returns the detected object types (windows/holes), the area in pixels and the computed area in meters.\n",
    "\n",
    "import cv2\n",
    "#import calibration # load calibration.py from the same folder first to obtain PPM at a set distance\n",
    "import numpy as np\n",
    " \n",
    "# Initialize videostream \n",
    "#Frame width and height can be modified depending on need with cap.set function\n",
    "\n",
    "# Each frame can be extracted separately from the capture variable (the videostream)\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# 'emptyFunction' function defined to be used by the 'Variables' Trackbar\n",
    " \n",
    "def emptyFunction(a):\n",
    "    pass\n",
    "# Define Threshold parameters (Variables) and Trackbars for variation: area size filtering and 2 thresholds for Canny Edges\n",
    "cv2.namedWindow(\"Variables\")\n",
    "cv2.resizeWindow(\"Variables\",640,240)\n",
    "cv2.createTrackbar(\"Thresh_1\",\"Variables\",172,255,emptyFunction) # Threshold parameter 1\n",
    "cv2.createTrackbar(\"Thresh_2\",\"Variables\",30,255,emptyFunction) # Threshold parameter 2\n",
    "cv2.createTrackbar(\"Area\",\"Variables\",7000,121500,emptyFunction) # Area filtering variable\n",
    "\n",
    "# Function that takes input 'img' and returns output 'imgContour' (contours and labels drawn over original image) \n",
    "def getContours(img,imgContour):\n",
    "  # Extract EXTERNAL contours from the input image, img=Dilated_img, when the function will be called\n",
    "  contours, unused_var = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)# simple-less no of points\n",
    "  # Draw external contours over the output image, imgContour will be a copy of img initially\n",
    "  cv2.drawContours(imgContour,contours,-1,(255,0,255),3)\n",
    "  # Iterate over all contours (cnt)\n",
    "  for cnt in contours:\n",
    "    # Calculate area of each contour (in pixels)\n",
    "    area = cv2.contourArea(cnt)\n",
    "    # Set an arbitraty minimum area, from Area trackbar in 'Variables' tab\n",
    "    areamin=cv2.getTrackbarPos(\"Area\",\"Variables\")\n",
    "    # Any contour with less than areamin will be ignored (reduces unwanted noise)\n",
    "    if area > areamin:\n",
    "      # If area is large enough, draw the contours over the output image, imgContour\n",
    "      cv2.drawContours(imgContour,cnt,-1,(255,0,255),3)\n",
    "       # Compute the contour perimeter / length (True=only closed contours considered)\n",
    "      perimeter=cv2.arcLength(cnt,True)\n",
    "      # Approximate the shape of object, contours (cnt) as input, resolution=0.01*length, True=only closed contours\n",
    "      shape_approximation = cv2.approxPolyDP(cnt, 0.01*perimeter, True)# contains a number of points, used in determining shapes: length(shape_approximation)\n",
    "      # Calculates minimum upright bounding rectangle for the specific point set (object)- outputs start coordinates (x,y) (top left) and rectangle dimensions (w,h)\n",
    "      x,y,w,h=cv2.boundingRect(shape_approximation)\n",
    "      # Draw bounding box over object: input the start coords (x,y) and end coords (x+w,y+h)\n",
    "      cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "      # Display number of points of an object, area in pixels and CENTER POINT\n",
    "      cv2.putText(imgContour, \"No. of Points: \" + str(len(shape_approximation)), (x, y + 20), cv2.FONT_HERSHEY_COMPLEX, .5,\n",
    "                        (0, 0, 255), 1)\n",
    "      cv2.putText(imgContour, \"Area [p]: \" + str(int(area)), (x, y + 40), cv2.FONT_HERSHEY_COMPLEX, 0.5,\n",
    "                        (0, 0, 255), 1)\n",
    "      cv2.putText(imgContour, \"Center [p]: (\"+ str(x+int(w/2)) +\",\"+ str(y+int(h/2))+ \")\", (x, y + 80), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1)\n",
    "      # If an object has 4 or 5 points, it is a window (rectangular window assumed)\n",
    "      if len(shape_approximation)>=4 and len(shape_approximation)<=5:\n",
    "        cv2.putText(imgContour, \"Window\", (x, y + 60), cv2.FONT_HERSHEY_COMPLEX, .5,\n",
    "                        (0, 0, 255), 1)\n",
    "        # Draw center point of window/rectangle in red\n",
    "        cv2.circle(imgContour, (x+int(w/2),y+int(h/2)), radius=0, color=(0, 0, 255), thickness=5)\n",
    "\n",
    "        # AREA IN METERS CALCULATIONS, using the calibration.py script\n",
    "        DC1=0.12 # input variable distance measured by sensor [m] from drone to wall\n",
    "        PPM1=calibration.PPM*calibration.DC/DC1 # PPM' at that exact distance (DC1)\n",
    "        print(\"PPM at actual distance DC1: \"+ str(PPM1))\n",
    "        A_p1=area # Area in pixels of actual object\n",
    "        print(\"Actual object area in pixels: \"+ str(A_p1))\n",
    "        A_m1 = A_p1 / PPM1 # REQUIRED AREA of object [m^2]\n",
    "        print(\"Actual object area in meters: \"+ str(A_m1)) # REQUIRED AREA OF ENTRY POINT DISPLAYED IN TERMINAL\n",
    "        # Display area [m^2] on image\n",
    "        cv2.putText(imgContour, \"Area [m^2]: \" + str(A_m1), (x, y + 100), cv2.FONT_HERSHEY_COMPLEX, 0.5,\n",
    "                        (0, 255, 0), 1)\n",
    "      # If an object has >5 points, it is a hole (circular,elliptic,irregular shaped holes assumed)\n",
    "      else: \n",
    "        cv2.putText(imgContour, \"Hole\", (x, y + 60), cv2.FONT_HERSHEY_COMPLEX, .5,\n",
    "                        (0, 0, 255), 1)\n",
    "        # Draw center point of hole in red\n",
    "        cv2.circle(imgContour, (x+int(w/2),y+int(h/2)), radius=0, color=(0, 0, 255), thickness=5)\n",
    "\n",
    "# Run for every frame in the videostream; img = each frame \n",
    "while True:\n",
    "    grabbed, img = capture.read() # grab the frames and store them as img\n",
    "    imgContour = img.copy() # initialize the output imgContour as a copy of img\n",
    "    # Apply Gaussian Blur Filter, (9,9) kernel to smooth the image and reduce noise  \n",
    "    Blur_img = cv2.GaussianBlur(img, (9, 9), 1)\n",
    "    # Convert to Greyscale\n",
    "    Gray_img = cv2.cvtColor(Blur_img, cv2.COLOR_BGR2GRAY)\n",
    "    # Set treshold values for Canny Edge Detector, using trackbars in the 'Variables' window  \n",
    "    thresh_1 = cv2.getTrackbarPos(\"Thresh_1\", \"Variables\")\n",
    "    thresh_2 = cv2.getTrackbarPos(\"Thresh_2\", \"Variables\")\n",
    "    # Apply Canny Edge Detection filter with variable thresholds, tested defaults are 172,140, can be varied\n",
    "    Canny_img = cv2.Canny(Gray_img,thresh_1,thresh_2)\n",
    "    # Creating convolution kernel used for Dilation  \n",
    "    kernel = np.ones((5, 5))\n",
    "    # Dilating the Canny Edges in order to accentuate the shape, iterations=1 for most accurate object area\n",
    "    Dilated_img = cv2.dilate(Canny_img, kernel, iterations=1)\n",
    "    # Use defined function to draw the boxel, labels and areas using the Dilated_img as input, for accurate detection, and the copy of img (imgContour) as the output image. Thus, the boxes, labels and areas will appear on the original un-filtered videostream live.\n",
    "    getContours(Dilated_img, imgContour)\n",
    "    # Display original videostream frames with contours, boxes, labels and areas\n",
    "    cv2.imshow(\"Contours\", imgContour)\n",
    "    # Stop script upon pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e09adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
